<!DOCTYPE html>
<head>
<html lang="en">
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,400;0,500;0,700;1,200&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css" />
  <title>CYBERPUNK</title>
  </head>
  <body>
    <nav class="navbar">
      <div class="brand-title">
     <a href="index.html"> <img src="images/logo.png" alt="logo de la pagina" class="logo"></a></div>
     <a href="#" class="toggle-button">
       <span class="bar"></span>
       <span class="bar"></span>
       <span class="bar"></span>
     </a>
     <div class="navbar-links">
      <ul>
        <li><a href="books.html">BOOKS</a></li>
        <li><a href="articles.html">ARTICLES</a></li>
        <li><a href="tech.html">TECH</a></li>
        </ul>
      </div>
    </nav>

        
   
    <div class="article">
      <h2>Why Roblox is the C-64 of our time.</h2>
      <p class="texto-fecha">February 25 2022</p>
      <img class="imagen-articulo" src="images/c-64.png" alt="imagen de computador commodore c-64">
 
      <div class="texto-articulo">
      <h3>Katerine Cerrato</h3><br>
 
      <p class="pArticles">We're glad to have the opportunity to share his thoughts on why Roblox is the C-64 of our time, and his mission to empower an emerging generation of software creators, both non-coders and coders.</p> 
 
      <p class="pArticles">Just showing this image to a coder about my age likely puts them at risk of launching into a raving nostalgic rant. However, most, if not all, of my childhood friends that later found a career/lifestyle in coding started with this blue screen (replacing, or at least competing with a likely unhealthy obsession with Lego).</p>
 
      <p class="pArticles">From C-64, we graduated to AMOS (if you were staying true to Commodore), the beautiful piece of software written by François Lionet and Constantin Sotiropoulos that became one of the best selling non-game titles for the Amiga with over 40,000 copies sold. And when you moved on to the PC, the threshold of learning C and C++ just didn’t feel very steep.</p>
 
      <p class="pArticles">The crux is that everyone had to get past this blue wall. Even if all you wanted was to get into Ghosts 'n Goblins as fast as possible, you still needed to pick up a few commands. And the C-64 shipped with the BASIC manual. What if while you were unboxing your shiny new iPad, the first thing you picked up was a 200-page book on Swift and Objective-C. I bet a big chunk of this generation of software developers were accidental coders. And the booming game industry in the Nordics (where I live) likely owes a lot to these old machines.
 
      </p>
 
      <p class="pArticles">Then we entered the dark ages of the late 90s and the first decades of the 2000s. At this time, when you inspected someone's TV setup, all you found were Nintendos, Playstations and X-Boxes, completely useless with their user-friendly interfaces and their read-only cartridges and CDs. If you wanted to code on these machines (which was great), you already needed a degree in computer science and the patience to ply through guides on homebrew hacking. If you happened to be the weird kid that got a PC (or were forced by your parents), you should consider yourself lucky. But even then, the step to get into coding was not obvious.</p>
 
      <p class="pArticles">Another thing, at this time, games (which was the likely ambition for the aspiring coders) were getting good. The graphics were fantastic (thanks to all the old C-64 coders now working day and night at the fancy game studios). The 2D blocky Italian plumber had been replaced by huge immersive 3D worlds filled with hundreds of beautifully animated characters. Anything you happened to create (if you had the skills and drive to pick up programming) would likely look pretty embarrassing in comparison and certainly not something that got you any nerd street cred (some might argue that this was the time of early web with HTML and Javascript playing the sort of the same role, but is that really coding?).</p>
 
      <p class="pArticles">Fast forward to about 2016 when a sort of awkward but charming game creation system called Roblox (created by David Baszucki and Erik Cassel in 2004 and released in 2006) started to gain popularity. I know that it has faced criticism for marketing microtransactions to young children, but I’m talking primarily about Roblox Studio.
 
      </p>
 
      <p class="pArticles">Roblox allows players to create their own games using its proprietary engine, Roblox Studio, which other users can then play. The tool shares much of its DNA with existing professional game engines but at a much simpler level. Lua is the programming language of choice, and it bears a lot of resemblance to BASIC but with more modern software development concepts. Most games produced using Roblox Studio are developed by minors, and 20 million games a year are produced using it.</p>
 
      <p class="pArticles">It has never been easier for a kid to get into serious programming. YouTube is littered with videos and tutorials on pretty much every Roblox concept you can imagine. And from the most unexpected sources as well -  while trying to learn the engine, I’ve found myself repeatedly watching videos by 8-year olds on how to do Tween animation or custom Camera scripts. </p>
 
      <p class="pArticles">But I would argue that the most crucial aspect that is often overlooked is that the general quality of Roblox games is pretty bad, which is great! It means that the difference between what my eldest son and I are creating together is not too far from that trendy crazy tycoon game, “obby” or pet simulator of the time. Making a new game does not seem insurmountable since it is not expected to be a AAA title.</p>
 
      <p class="pArticles">I don’t think I can overstate the importance of this! Spending time writing games with my kids is amazing, and seeing how fast their skills develop is something I couldn’t possibly have imagined 35 years ago.</p>
 
      <p class="pArticles">Of course, each generation of platforms enables new creativity and businesses unimaginable to the last. And I hope that I’m part of contributing to the next generation as well.</p>
 
      <p class="pArticles">I’m a co-founder and software developer working at Noodl, a design programming platform built around a visual programming model. Our mission is to empower an emerging generation of software creators, both non-coders and coders alike, with tools that enable them to create visionary software. </p>
 
      <p class="pArticles">The good news is that my son has already been producing apps in Noodl, and this makes me believe I’m on the right track.</p>
      <p>Also published <a href="https://www.noodl.net/post/why-roblox-is-the-c-64-of-our-time?ref=hackernoon.com">HERE.</a> </p>
         </div>
    </div>
    <div class="article">
      <h2>Building a Metaverse For Everyone</h2>
      <p class="texto-fecha">February 21 2022</p>
      <img class="imagen-articulo" src="images/metaverse.jpg" alt="imagen de computador commodore c-64">
 
      <div class="texto-articulo">
      <h3>Biswa Sengupta</h3><br>
 
      <p class="pArticles">Most of us have day jobs with set routines, responsibilities, and deliverables. Often, the mind wanders off, and as humans, we try to gauge alternative possibilities. What happens if I take the burden from one team member and add another team member to a project, suggest something to the executive leadership team, what should we cook for dinner, restaurant for the weekend, etc.? They are our banal thought processes. We are constantly juggling cause and effect and choosing the best of outcomes. Humans, in general, can do all this reasoning in the blink of an eye, which is the prophesized unique selling proposition of Artificial General Intelligence. Such decisions and their repercussions show us a parallel future that may exist — enter Metaverse, an environment that is a virtual space with augmented and virtual realities embedded therein. Think of people, cities, countries that exist digitally instead of flesh and bone or mortar and steel. In simple terms, Metaverse brings together the power of simulation technologies that we have championed over the last century and builds virtual worlds (almost like a video game) where people can have an immersive experience.</p> 
 
      <p class="pArticles">Little did Neal Stephenson (author of Snow Crash (1992) and the inventor of the term metaverse) know that this term will be foundational in building billion-dollar industries 30 years later. Metaverse has much excitement, and many companies are creating a digital presence. Nike has announced that it will create Nikeland on the metaverse platform Roblox. It will closely resemble the real physical Nike’s headquarters, and users can dress their avatars using Nike commodities, buy products from the virtual store, etc. Another metaverse platform Decentraland is hosting a first-of-its-kind Metaverse Fashion Week with lots of brands displaying their new collection and letting catwalk avatars walk the ramp. Some brands will be offering digital couture for the avatar where buyers can choose to sell the item and redeem the NFT (virtual currency — Non-fungible token) to buy a physical complement. Retailers like Walmart anticipate venturing into the Metaverse, creating their cryptocurrency and collection of NFTs. Instead of adding your milk and bread into a cart, we might be able to move around a store replica and buy our groceries (obviously delivered to our abode — we still cannot eat virtual bread and butter). Jokes apart, many exciting business models have been evolving in this space.</p>
 
      <p class="pArticles">Advertising is yet another use case, as people embedded in the Metaverse can buy commodities for their digital self. This buying behavior will undoubtedly percolate into their real life. Instead of typing amazon.com on your web browser, we walk to the promised virtual land and buy the crockery we need for our dinner party by sieving through various advertised products in this virtual space (instead of your 2D computer screen). It indeed has taken 20+ years to get a seamless user interface for the 2D e-shopping world; I imagine, given the speed of innovation, one can get it right in half the time. Other use cases range from purchasing virtual avatars, buying homes to immersive learning in virtual classrooms. So, much scope for next-generation advertisement companies.</p>
 
      <p class="pArticles">What’s in for the technologist? Metaverse can be a melting pot of machine learning technologies like computer vision (CV), Natural Language Processing (NLP) and reinforcement learning (RL). We currently have a myopic view — use NLP to create voice agents, CV to figure missed items on a shelf or RL for scheduling and planning. Only some people have seen what happens when we bring voice and vision to make decisions. Google Deepmind, FAIR, OpenAI, and many other labs have been championing the decision-making aspect of artificial intelligence. No limits of technological advancements in voice and vision alone can take us close to Artificial General Intelligence unless we can use these sensations in a concerted way to take decisions. Thus, Metaverse may become a virtual experimental ground — a massive multiplayer game (RL folks, please think more about multi-agent RL and your favorite recipes for decentralized partially observable Markov Decision Processes).</p>
 
      <p class="pArticles">Significant technology corporations like Microsoft and Meta (formerly Facebook) and financial services firms like Morgan Stanley have been flocking to integrate some form of metaverse offering in their product line. Virtual reality headset companies (Oculus, Pico, Varjo, Vive, etc.) that enable us to enter Metaverse and hardware manufacturers from MediaTek and TSMC to Luxshare have invested in building the hardware for the foundational Metaverse. Despite decades of development, these “entry tickets to metaverse” are bulky to wear and expensive to own. The whole point of creating a future parallel to reality (the Metaverse) is to have an immersive experience. Anything less from a user-experience point of view, we hit the first snag from a hardware point of view.</p>
 
      <p class="pArticles">Additionally, shouldn’t we start thinking about people who cannot see, hear or have an anxiety disorder (this was reignited as I watched Netflix’s As We See It). Or are we again going to create a judgmental metaverse? There are other issues concerning data and security, payment systems, legal jurisdiction in Metaverse that spans countries, ownership rights, etc. — more on these in a subsequent post.</p>
 
      <p class="pArticles">Being a machine learning scientist in academia and a technology executive in the industry, I have learned to see ideas such as Metaverse (and its earlier avatar Second Life and a few others) at the intersection of technology and product, but with a lens of ‘value’. Even crucially, will this have customer adoption? Such a thought process quickly becomes labored. Much as the promise is Metaverse becoming a virtual space where people can “feel” physically and emotionally present — are we there yet? Not yet. Will we buy such a system whenever it is available? Maybe. The next question we will ask is what for? Remember, all in all, we will have to devote physical (not virtual) time, money, and energy to interact with Metaverse. At the same time, I can see it being parallel to playing a videogame building community with your virtual neighbors but do we have the cognitive capacity to live a parallel life. Don’t we already have an information overload? Yes, tons of companies would be minting money showing VCs and users the promised metaverse land, but it would be crucial to ask what the product is? Build it, and the customer will come flocking mantra may not work. </p>
 
      <p class="pArticles">So, what can work? In my opinion, the first step towards the Metaverse is unleashed when you can use it to (a) make decisions and (b) use it as a synthetic world for machine learning (ML) data generation. One needs to build the product-market fit incrementally. Otherwise, the customer adoption argument becomes quite strained if industries start opening “shops” in virtual spaces and using digital currencies or Non-fungible Tokens for buying/selling digital assets. The baby step towards Metaverse is Digital Twins, again an age-old concept. Take a small piece of the natural world, say a retail store, and use a dumb-down metaverse (the digital twin) to enable real-time visibility of all assets (commodities, store associates, supply chain flows, etc.). Then use technologies like computer vision to measure real-time supply-demand here-and-now at the store. Natural language processing sieves through thousands of correspondences and tells you what tasks need to be done. Finally, under the constraints of the digital twin, reinforcement learning makes decisions unfolding futures. This will help store managers have a real-time view of the store operations and take the nascent field of Digital Twins to make usable decisions. Technologically, it allows us to combine various voice and vision attributes and take optimal decisions. Don’t we all want to make informed decisions? I bet we do.</p>
 
      <p class="pArticles">The other baby step towards the Metaverse surrounds the digital twin again, but this time with a view of generating synthetic data. Our friends at Unity Technologies are already championing this line of thought, along with many other startups and technology companies. The central concept behind all of this is domain randomization. Digital twin, a subset of the Metaverse idea, enables us to create synthetic worlds and various subsets of the same world. What happens if my bedroom is painted red instead of white, the roads that I walk on are pebbled instead of concrete, change the visibility statistics (standard computer graphics tricks), etc. For example, most deep learning-based computer vision algorithms take a ton of training data. The digital twin (if constructed with rigor to reduce covariance shift from a real environment) can supply us with annotated synthetic data. Be it millions of kilometers of driving data for self-driving cars or hundreds of permutations for objects under different view statistics. Similarly, RL algorithms have a hard time generalizing when the domain is randomized, i.e., random changes in material (texture, color), light direction, light conditions, and placement of objects. The metaverse concept can help us alleviate some of the data efficiency problems.

      </p>
 
      <p class="pArticles">
        #
        
        Blurring the Lines Between Real and Virtual Spaces
        
        
        Most of us have day jobs with set routines, responsibilities, and deliverables. Often, the mind wanders off, and as humans, we try to gauge alternative possibilities. What happens if I take the burden from one team member and add another team member to a project, suggest something to the executive leadership team, what should we cook for dinner, restaurant for the weekend, etc.? They are our banal thought processes. We are constantly juggling cause and effect and choosing the best of outcomes. Humans, in general, can do all this reasoning in the blink of an eye, which is the prophesized unique selling proposition of Artificial General Intelligence. Such decisions and their repercussions show us a parallel future that may exist — enter Metaverse, an environment that is a virtual space with augmented and virtual realities embedded therein. Think of people, cities, countries that exist digitally instead of flesh and bone or mortar and steel. In simple terms, Metaverse brings together the power of simulation technologies that we have championed over the last century and builds virtual worlds (almost like a video game) where people can have an immersive experience.
        
        #
        
        Immersive Experience
        Little did Neal Stephenson (author of Snow Crash (1992) and the inventor of the term metaverse) know that this term will be foundational in building billion-dollar industries 30 years later. Metaverse has much excitement, and many companies are creating a digital presence. Nike has announced that it will create Nikeland on the metaverse platform Roblox. It will closely resemble the real physical Nike’s headquarters, and users can dress their avatars using Nike commodities, buy products from the virtual store, etc. Another metaverse platform Decentraland is hosting a first-of-its-kind Metaverse Fashion Week with lots of brands displaying their new collection and letting catwalk avatars walk the ramp. Some brands will be offering digital couture for the avatar where buyers can choose to sell the item and redeem the NFT (virtual currency — Non-fungible token) to buy a physical complement. Retailers like Walmart anticipate venturing into the Metaverse, creating their cryptocurrency and collection of NFTs. Instead of adding your milk and bread into a cart, we might be able to move around a store replica and buy our groceries (obviously delivered to our abode — we still cannot eat virtual bread and butter). Jokes apart, many exciting business models have been evolving in this space.
        
        
        
        Advertising is yet another use case, as people embedded in the Metaverse can buy commodities for their digital self. This buying behavior will undoubtedly percolate into their real life. Instead of typing amazon.com on your web browser, we walk to the promised virtual land and buy the crockery we need for our dinner party by sieving through various advertised products in this virtual space (instead of your 2D computer screen). It indeed has taken 20+ years to get a seamless user interface for the 2D e-shopping world; I imagine, given the speed of innovation, one can get it right in half the time. Other use cases range from purchasing virtual avatars, buying homes to immersive learning in virtual classrooms. So, much scope for next-generation advertisement companies.
        
        
        
        What’s in for the technologist? Metaverse can be a melting pot of machine learning technologies like computer vision (CV), Natural Language Processing (NLP) and reinforcement learning (RL). We currently have a myopic view — use NLP to create voice agents, CV to figure missed items on a shelf or RL for scheduling and planning. Only some people have seen what happens when we bring voice and vision to make decisions. Google Deepmind, FAIR, OpenAI, and many other labs have been championing the decision-making aspect of artificial intelligence. No limits of technological advancements in voice and vision alone can take us close to Artificial General Intelligence unless we can use these sensations in a concerted way to take decisions. Thus, Metaverse may become a virtual experimental ground — a massive multiplayer game (RL folks, please think more about multi-agent RL and your favorite recipes for decentralized partially observable Markov Decision Processes).
        
        #
        
        Build it, and They Would Come Flocking…
        Significant technology corporations like Microsoft and Meta (formerly Facebook) and financial services firms like Morgan Stanley have been flocking to integrate some form of metaverse offering in their product line. Virtual reality headset companies (Oculus, Pico, Varjo, Vive, etc.) that enable us to enter Metaverse and hardware manufacturers from MediaTek and TSMC to Luxshare have invested in building the hardware for the foundational Metaverse. Despite decades of development, these “entry tickets to metaverse” are bulky to wear and expensive to own. The whole point of creating a future parallel to reality (the Metaverse) is to have an immersive experience. Anything less from a user-experience point of view, we hit the first snag from a hardware point of view.
        
        
        
        Additionally, shouldn’t we start thinking about people who cannot see, hear or have an anxiety disorder (this was reignited as I watched Netflix’s As We See It). Or are we again going to create a judgmental metaverse? There are other issues concerning data and security, payment systems, legal jurisdiction in Metaverse that spans countries, ownership rights, etc. — more on these in a subsequent post.
        
        
        
        Being a machine learning scientist in academia and a technology executive in the industry, I have learned to see ideas such as Metaverse (and its earlier avatar Second Life and a few others) at the intersection of technology and product, but with a lens of ‘value’. Even crucially, will this have customer adoption? Such a thought process quickly becomes labored. Much as the promise is Metaverse becoming a virtual space where people can “feel” physically and emotionally present — are we there yet? Not yet. Will we buy such a system whenever it is available? Maybe. The next question we will ask is what for? Remember, all in all, we will have to devote physical (not virtual) time, money, and energy to interact with Metaverse. At the same time, I can see it being parallel to playing a videogame building community with your virtual neighbors but do we have the cognitive capacity to live a parallel life. Don’t we already have an information overload? Yes, tons of companies would be minting money showing VCs and users the promised metaverse land, but it would be crucial to ask what the product is? Build it, and the customer will come flocking mantra may not work.
        
        
        
        So, what can work? In my opinion, the first step towards the Metaverse is unleashed when you can use it to (a) make decisions and (b) use it as a synthetic world for machine learning (ML) data generation. One needs to build the product-market fit incrementally. Otherwise, the customer adoption argument becomes quite strained if industries start opening “shops” in virtual spaces and using digital currencies or Non-fungible Tokens for buying/selling digital assets. The baby step towards Metaverse is Digital Twins, again an age-old concept. Take a small piece of the natural world, say a retail store, and use a dumb-down metaverse (the digital twin) to enable real-time visibility of all assets (commodities, store associates, supply chain flows, etc.). Then use technologies like computer vision to measure real-time supply-demand here-and-now at the store. Natural language processing sieves through thousands of correspondences and tells you what tasks need to be done. Finally, under the constraints of the digital twin, reinforcement learning makes decisions unfolding futures. This will help store managers have a real-time view of the store operations and take the nascent field of Digital Twins to make usable decisions. Technologically, it allows us to combine various voice and vision attributes and take optimal decisions. Don’t we all want to make informed decisions? I bet we do.
        
        
        
        The other baby step towards the Metaverse surrounds the digital twin again, but this time with a view of generating synthetic data. Our friends at Unity Technologies are already championing this line of thought, along with many other startups and technology companies. The central concept behind all of this is domain randomization. Digital twin, a subset of the Metaverse idea, enables us to create synthetic worlds and various subsets of the same world. What happens if my bedroom is painted red instead of white, the roads that I walk on are pebbled instead of concrete, change the visibility statistics (standard computer graphics tricks), etc. For example, most deep learning-based computer vision algorithms take a ton of training data. The digital twin (if constructed with rigor to reduce covariance shift from a real environment) can supply us with annotated synthetic data. Be it millions of kilometers of driving data for self-driving cars or hundreds of permutations for objects under different view statistics. Similarly, RL algorithms have a hard time generalizing when the domain is randomized, i.e., random changes in material (texture, color), light direction, light conditions, and placement of objects. The metaverse concept can help us alleviate some of the data efficiency problems.
        
        
        
        In summary, if channeled from an end-product discussion, the excitement for Metaverse can shape and most probably lessen the impedance mismatch between the product and the market needs. Unchecked false assumptions can kill companies, no matter how technically great the solution is. </p>
 
      
         </div>
    </div>

    <!--aca vamos a empezar nuestro footer-->
<footer>

  <div class="footer-box">
    <ul>
      <li><a href="">something</a></li>
      <li><a href="">expecting</a></li>
      <li><a href="">airport</a></li>
      <li><a href="">artificial</a></li>
    </ul>
  </div>
  <div class="footer-box">
    <ul>
      <li><a href="">tension</a></li>
      <li><a href="">brains</a></li>
      <li><a href="">important</a></li>
      <li><a href="">dreamed</a></li>
    </ul>
  </div>   
</footer>

<div class="footer-links-horizontal">
  <p>Terms of use</p><p>Contact</p><p>User Agreement</p><p>About</p>
</div>


    <script src="js/app.js"></script>
  </body>
</html>

